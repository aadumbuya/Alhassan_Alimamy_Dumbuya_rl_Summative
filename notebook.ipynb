{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f53LOpH5ZMd",
        "outputId": "fba5b6ba-c903-4d1f-af70-520d1c63a05d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting mujoco\n",
            "  Downloading mujoco-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco) (1.12.2)\n",
            "Collecting glfw (from mujoco)\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco) (3.1.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco) (3.21.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mujoco, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed glfw-2.8.0 mujoco-3.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3 gymnasium[mujoco] mujoco matplotlib imageio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vJmUc7OSwZ9X"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "class AUVNavigationEnv(gym.Env):\n",
        "    \"\"\"Enhanced AUV Navigation Environment with Realistic Visualization\"\"\"\n",
        "    metadata = {'render_modes': ['human']}\n",
        "\n",
        "    def __init__(self):\n",
        "        super(AUVNavigationEnv, self).__init__()\n",
        "\n",
        "        # Action space: Forward, Backward, Left, Right, Ascend, Descend\n",
        "        self.action_space = spaces.Discrete(6)\n",
        "\n",
        "        # Observation space: Position (x, y, z), Battery, Distance to goal\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([0, 0, 0, 0, 0]),\n",
        "            high=np.array([100, 100, 50, 100, 50]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Obstacles and environment objects\n",
        "        self.num_obstacles = 10\n",
        "        self.num_objects = 5\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.auv_position = np.array([10, 10, 5])\n",
        "        self.goal_position = np.array([90, 90, 30])\n",
        "        self.battery = 200\n",
        "        self.steps = 0\n",
        "\n",
        "        self.obstacles = np.random.randint(0, 100, size=(self.num_obstacles, 3))\n",
        "        self.objects = np.random.randint(0, 100, size=(self.num_objects, 3))\n",
        "\n",
        "        distance = np.linalg.norm(self.goal_position - self.auv_position)\n",
        "        obs = np.concatenate((self.auv_position, [self.battery], [distance]))\n",
        "        return obs, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        movement = {\n",
        "            0: np.array([1, 0, 0]),  # Forward\n",
        "            1: np.array([-1, 0, 0]),  # Backward\n",
        "            2: np.array([0, 1, 0]),  # Move Left\n",
        "            3: np.array([0, -1, 0]), # Move Right\n",
        "            4: np.array([0, 0, 1]),  # Ascend\n",
        "            5: np.array([0, 0, -1])  # Descend\n",
        "        }\n",
        "\n",
        "        prev_distance = np.linalg.norm(self.goal_position - self.auv_position)\n",
        "        new_position = np.clip(self.auv_position + movement[action], [0, 0, 0], [100, 100, 50])\n",
        "\n",
        "        for obs in self.obstacles:\n",
        "            if np.array_equal(new_position, obs):\n",
        "                return np.concatenate((self.auv_position, [self.battery], [prev_distance])), -10, False, False, {}\n",
        "\n",
        "        self.auv_position = new_position\n",
        "        self.battery = max(0, self.battery - 1)\n",
        "        distance = np.linalg.norm(self.goal_position - self.auv_position)\n",
        "\n",
        "        reward = (prev_distance - distance) * 10\n",
        "        done = distance < 5 or self.battery <= 0\n",
        "        obs = np.concatenate((self.auv_position, [self.battery], [distance]))\n",
        "        return obs, reward, done, False, {}\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        \"\"\"Renders a high-quality, visually rich environment with OpenCV and Matplotlib.\"\"\"\n",
        "        img = np.ones((500, 500, 3), dtype=np.uint8) * 255  # White background\n",
        "\n",
        "        # Draw underwater gradient\n",
        "        for i in range(500):\n",
        "            img[i, :, :] = [255 - i//2, 255 - i//3, 255]  # Blue gradient\n",
        "\n",
        "        scale = 5\n",
        "\n",
        "        # Draw goal\n",
        "        goal_x, goal_y = self.goal_position[:2] * scale\n",
        "        cv2.circle(img, (int(goal_x), int(goal_y)), 10, (0, 255, 0), -1)\n",
        "        cv2.putText(img, \"Goal\", (int(goal_x) + 10, int(goal_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "        # Draw AUV\n",
        "        auv_x, auv_y = self.auv_position[:2] * scale\n",
        "        cv2.circle(img, (int(auv_x), int(auv_y)), 10, (255, 0, 0), -1)\n",
        "        cv2.putText(img, \"AUV\", (int(auv_x) + 10, int(auv_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
        "\n",
        "        # Draw obstacles\n",
        "        for obs in self.obstacles:\n",
        "            obs_x, obs_y = obs[:2] * scale\n",
        "            cv2.rectangle(img, (int(obs_x) - 5, int(obs_y) - 5), (int(obs_x) + 5, int(obs_y) + 5), (0, 0, 255), -1)\n",
        "\n",
        "        # Draw environmental objects\n",
        "        for obj in self.objects:\n",
        "            obj_x, obj_y = obj[:2] * scale\n",
        "            cv2.circle(img, (int(obj_x), int(obj_y)), 5, (128, 128, 128), -1)\n",
        "\n",
        "        # Add HUD Information\n",
        "        cv2.putText(img, f\"Battery: {self.battery}\", (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "        cv2.putText(img, f\"Distance: {np.linalg.norm(self.goal_position - self.auv_position):.2f}\", (10, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "        # Display Title\n",
        "        cv2.putText(img, \"AUV Navigation Environment\", (100, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 3)\n",
        "\n",
        "        #cv2_imshow(\"AUV Navigation\", img)\n",
        "        cv2.waitKey(1)\n",
        "        return img\n",
        "\n",
        "    def close(self):\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrraQtZL5kv8",
        "outputId": "535aab18-9264-4319-f67f-a096678c5e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Logging to ./ppo_auv_log/PPO_2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 49.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 593      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 97.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019624107 |\n",
            "|    clip_fraction        | 0.326       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | -0.00272    |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 93.1        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.05       |\n",
            "|    value_loss           | 285         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=5000, episode_reward=314.57 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 200        |\n",
            "|    mean_reward          | 315        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 5000       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01665356 |\n",
            "|    clip_fraction        | 0.321      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.73      |\n",
            "|    explained_variance   | 0.0102     |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 177        |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0468    |\n",
            "|    value_loss           | 389        |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    fps             | 404      |\n",
            "|    iterations      | 3        |\n",
            "|    time_elapsed    | 15       |\n",
            "|    total_timesteps | 6144     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 280         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 393         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018531939 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.0874      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 480         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0358     |\n",
            "|    value_loss           | 916         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=850.44 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 850         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 10000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018374998 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | 0.0642      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 894         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0272     |\n",
            "|    value_loss           | 1.83e+03    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 368      |\n",
            "| time/              |          |\n",
            "|    fps             | 380      |\n",
            "|    iterations      | 5        |\n",
            "|    time_elapsed    | 26       |\n",
            "|    total_timesteps | 10240    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 434         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 375         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010211317 |\n",
            "|    clip_fraction        | 0.0625      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.0622      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.33e+03    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    value_loss           | 2.81e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 491         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 378         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009542348 |\n",
            "|    clip_fraction        | 0.0392      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.44       |\n",
            "|    explained_variance   | 0.0293      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.84e+03    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0134     |\n",
            "|    value_loss           | 3.47e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=314.57 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 315         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 15000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012329341 |\n",
            "|    clip_fraction        | 0.0741      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.39       |\n",
            "|    explained_variance   | 0.0469      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.99e+03    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    value_loss           | 4.23e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 538      |\n",
            "| time/              |          |\n",
            "|    fps             | 369      |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 16384    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 586         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 49          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007508138 |\n",
            "|    clip_fraction        | 0.00962     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.0556      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.19e+03    |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00754    |\n",
            "|    value_loss           | 4.42e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=684.74 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 200          |\n",
            "|    mean_reward          | 685          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 20000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020969403 |\n",
            "|    clip_fraction        | 0.00581      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.147        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.32e+03     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00521     |\n",
            "|    value_loss           | 5.08e+03     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 637      |\n",
            "| time/              |          |\n",
            "|    fps             | 366      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 55       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | 726        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 367        |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 61         |\n",
            "|    total_timesteps      | 22528      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00877219 |\n",
            "|    clip_fraction        | 0.00835    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.26      |\n",
            "|    explained_variance   | 0.14       |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 2.56e+03   |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.00716   |\n",
            "|    value_loss           | 5.54e+03   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 803         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 66          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006967313 |\n",
            "|    clip_fraction        | 0.00474     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.114       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.47e+03    |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00624    |\n",
            "|    value_loss           | 5.14e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=871.43 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 200          |\n",
            "|    mean_reward          | 871          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 25000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021676351 |\n",
            "|    clip_fraction        | 0.00635      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.22        |\n",
            "|    explained_variance   | 0.182        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.44e+03     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00585     |\n",
            "|    value_loss           | 5.51e+03     |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 871      |\n",
            "| time/              |          |\n",
            "|    fps             | 364      |\n",
            "|    iterations      | 13       |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 26624    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | 913          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045967153 |\n",
            "|    clip_fraction        | 0.00313      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.188        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.14e+03     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00481     |\n",
            "|    value_loss           | 5.84e+03     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=659.76 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 660         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 30000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008812075 |\n",
            "|    clip_fraction        | 0.0293      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | 0.158       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3e+03       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00922    |\n",
            "|    value_loss           | 5.59e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 941      |\n",
            "| time/              |          |\n",
            "|    fps             | 360      |\n",
            "|    iterations      | 15       |\n",
            "|    time_elapsed    | 85       |\n",
            "|    total_timesteps | 30720    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | 965          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 90           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040095868 |\n",
            "|    clip_fraction        | 0.0135       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.176        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.64e+03     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00259     |\n",
            "|    value_loss           | 5.77e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 988         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 96          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008368462 |\n",
            "|    clip_fraction        | 0.000586    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.28        |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3e+03       |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00198    |\n",
            "|    value_loss           | 5.76e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=35000, episode_reward=314.57 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 315         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 35000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013449694 |\n",
            "|    clip_fraction        | 0.0301      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.245       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.86e+03    |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00758    |\n",
            "|    value_loss           | 5.83e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 999      |\n",
            "| time/              |          |\n",
            "|    fps             | 360      |\n",
            "|    iterations      | 18       |\n",
            "|    time_elapsed    | 102      |\n",
            "|    total_timesteps | 36864    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.01e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 108         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013552093 |\n",
            "|    clip_fraction        | 0.0509      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.311       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.88e+03    |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00814    |\n",
            "|    value_loss           | 5.63e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=314.57 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 315         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010507075 |\n",
            "|    clip_fraction        | 0.0084      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.225       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.65e+03    |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00452    |\n",
            "|    value_loss           | 5.65e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 1.01e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 359      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 114      |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.02e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 119         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014028423 |\n",
            "|    clip_fraction        | 0.0221      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.271       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.26e+03    |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00564    |\n",
            "|    value_loss           | 5.9e+03     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=45000, episode_reward=314.57 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 315         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 45000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010844105 |\n",
            "|    clip_fraction        | 0.0126      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.244       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.61e+03    |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00615    |\n",
            "|    value_loss           | 5.24e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 1.02e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 22       |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 45056    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.02e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 131         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013082188 |\n",
            "|    clip_fraction        | 0.0437      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | 0.27        |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.33e+03    |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0069     |\n",
            "|    value_loss           | 5.51e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | 1.02e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 360        |\n",
            "|    iterations           | 24         |\n",
            "|    time_elapsed         | 136        |\n",
            "|    total_timesteps      | 49152      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01541911 |\n",
            "|    clip_fraction        | 0.0912     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.13      |\n",
            "|    explained_variance   | 0.314      |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 2.7e+03    |\n",
            "|    n_updates            | 230        |\n",
            "|    policy_gradient_loss | -0.0114    |\n",
            "|    value_loss           | 5.53e+03   |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=880.45 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 880         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 50000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012899282 |\n",
            "|    clip_fraction        | 0.0315      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.14       |\n",
            "|    explained_variance   | 0.367       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.55e+03    |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00859    |\n",
            "|    value_loss           | 5.6e+03     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 1.02e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 25       |\n",
            "|    time_elapsed    | 142      |\n",
            "|    total_timesteps | 51200    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.03e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 148         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007188393 |\n",
            "|    clip_fraction        | 0.0131      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.435       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.57e+03    |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00469    |\n",
            "|    value_loss           | 5.24e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=55000, episode_reward=732.75 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 200          |\n",
            "|    mean_reward          | 733          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 55000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029517154 |\n",
            "|    clip_fraction        | 0.00474      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.48         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.38e+03     |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.004       |\n",
            "|    value_loss           | 5.66e+03     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 1.03e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 27       |\n",
            "|    time_elapsed    | 154      |\n",
            "|    total_timesteps | 55296    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.03e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 159         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008526626 |\n",
            "|    clip_fraction        | 0.0239      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.409       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.2e+03     |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00472    |\n",
            "|    value_loss           | 5.66e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | 1.03e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 360        |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 164        |\n",
            "|    total_timesteps      | 59392      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01483022 |\n",
            "|    clip_fraction        | 0.0367     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.15      |\n",
            "|    explained_variance   | 0.421      |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 2.36e+03   |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | -0.00769   |\n",
            "|    value_loss           | 5.45e+03   |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=898.47 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 898         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 60000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007055973 |\n",
            "|    clip_fraction        | 0.0274      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.329       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.56e+03    |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.00945    |\n",
            "|    value_loss           | 4.94e+03    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 1.03e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 357      |\n",
            "|    iterations      | 30       |\n",
            "|    time_elapsed    | 171      |\n",
            "|    total_timesteps | 61440    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.03e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 176         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010339012 |\n",
            "|    clip_fraction        | 0.00923     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.483       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.48e+03    |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.00508    |\n",
            "|    value_loss           | 5.21e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=65000, episode_reward=887.74 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 888         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 65000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014838161 |\n",
            "|    clip_fraction        | 0.0812      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.405       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.59e+03    |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.0115     |\n",
            "|    value_loss           | 5.25e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 1.03e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 357      |\n",
            "|    iterations      | 32       |\n",
            "|    time_elapsed    | 183      |\n",
            "|    total_timesteps | 65536    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | 1.03e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 188          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0093567595 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.17        |\n",
            "|    explained_variance   | 0.468        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.49e+03     |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00425     |\n",
            "|    value_loss           | 5.29e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.03e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 194         |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009475109 |\n",
            "|    clip_fraction        | 0.0062      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.49        |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.75e+03    |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.00411    |\n",
            "|    value_loss           | 5.06e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=1045.08 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 200          |\n",
            "|    mean_reward          | 1.05e+03     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 70000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053533297 |\n",
            "|    clip_fraction        | 0.00557      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.503        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.68e+03     |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00417     |\n",
            "|    value_loss           | 4.92e+03     |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 1.04e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 35       |\n",
            "|    time_elapsed    | 200      |\n",
            "|    total_timesteps | 71680    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.04e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 205         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003505276 |\n",
            "|    clip_fraction        | 0.00317     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.534       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.07e+03    |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.00372    |\n",
            "|    value_loss           | 5.2e+03     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=75000, episode_reward=1112.84 +/- 0.00\n",
            "Episode length: 180.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 180          |\n",
            "|    mean_reward          | 1.11e+03     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 75000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058477866 |\n",
            "|    clip_fraction        | 0.0135       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.46e+03     |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00641     |\n",
            "|    value_loss           | 5.28e+03     |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 1.04e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 37       |\n",
            "|    time_elapsed    | 211      |\n",
            "|    total_timesteps | 75776    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | 1.04e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 216         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002837762 |\n",
            "|    clip_fraction        | 0.00479     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.14       |\n",
            "|    explained_variance   | 0.561       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.55e+03    |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00354    |\n",
            "|    value_loss           | 5.26e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 199         |\n",
            "|    ep_rew_mean          | 1.05e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 222         |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012475772 |\n",
            "|    clip_fraction        | 0.0537      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | 0.508       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.61e+03    |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.00663    |\n",
            "|    value_loss           | 5.13e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=874.76 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 875         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008151259 |\n",
            "|    clip_fraction        | 0.0249      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0.576       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.47e+03    |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.00863    |\n",
            "|    value_loss           | 5.35e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 199      |\n",
            "|    ep_rew_mean     | 1.06e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 359      |\n",
            "|    iterations      | 40       |\n",
            "|    time_elapsed    | 228      |\n",
            "|    total_timesteps | 81920    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 198          |\n",
            "|    ep_rew_mean          | 1.06e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 233          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025622104 |\n",
            "|    clip_fraction        | 0.00137      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | 0.554        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.68e+03     |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    value_loss           | 5.36e+03     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=85000, episode_reward=888.66 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 200          |\n",
            "|    mean_reward          | 889          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 85000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033965474 |\n",
            "|    clip_fraction        | 0.015        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.553        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.38e+03     |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00352     |\n",
            "|    value_loss           | 5.09e+03     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 198      |\n",
            "|    ep_rew_mean     | 1.07e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 42       |\n",
            "|    time_elapsed    | 239      |\n",
            "|    total_timesteps | 86016    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 198          |\n",
            "|    ep_rew_mean          | 1.07e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 245          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076420996 |\n",
            "|    clip_fraction        | 0.00576      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.12        |\n",
            "|    explained_variance   | 0.541        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.28e+03     |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00755     |\n",
            "|    value_loss           | 5.14e+03     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=889.22 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 889         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 90000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008905785 |\n",
            "|    clip_fraction        | 0.0221      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.11       |\n",
            "|    explained_variance   | 0.56        |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.21e+03    |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.00766    |\n",
            "|    value_loss           | 4.91e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 198      |\n",
            "|    ep_rew_mean     | 1.07e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 44       |\n",
            "|    time_elapsed    | 251      |\n",
            "|    total_timesteps | 90112    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 198         |\n",
            "|    ep_rew_mean          | 1.07e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 256         |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013207246 |\n",
            "|    clip_fraction        | 0.00991     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0.521       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.94e+03    |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.0052     |\n",
            "|    value_loss           | 4.95e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 198         |\n",
            "|    ep_rew_mean          | 1.07e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 261         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013754368 |\n",
            "|    clip_fraction        | 0.07        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0.575       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.72e+03    |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    value_loss           | 4.69e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=95000, episode_reward=882.80 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 200         |\n",
            "|    mean_reward          | 883         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 95000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005334254 |\n",
            "|    clip_fraction        | 0.0141      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | 0.619       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.49e+03    |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.00374    |\n",
            "|    value_loss           | 4.76e+03    |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 198      |\n",
            "|    ep_rew_mean     | 1.07e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 47       |\n",
            "|    time_elapsed    | 268      |\n",
            "|    total_timesteps | 96256    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 198          |\n",
            "|    ep_rew_mean          | 1.07e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 273          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055554463 |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0.658        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.33e+03     |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.0074      |\n",
            "|    value_loss           | 4.76e+03     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=921.81 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 200          |\n",
            "|    mean_reward          | 922          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 100000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072750635 |\n",
            "|    clip_fraction        | 0.0393       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.635        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.41e+03     |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00626     |\n",
            "|    value_loss           | 4.72e+03     |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 198      |\n",
            "|    ep_rew_mean     | 1.07e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 358      |\n",
            "|    iterations      | 49       |\n",
            "|    time_elapsed    | 280      |\n",
            "|    total_timesteps | 100352   |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# Initialize environment\n",
        "env = AUVNavigationEnv()\n",
        "env = Monitor(env)  # Wrap for logging\n",
        "vec_env = DummyVecEnv([lambda: env])  # Vectorized environment\n",
        "\n",
        "# Hyperparameter Optimization\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    vec_env,\n",
        "    n_steps=2048,  # Larger batch for better updates\n",
        "    ent_coef=0.05,  # Less entropy for more exploitation\n",
        "    gamma=0.99,  # Discount factor\n",
        "    learning_rate=1e-4,  # Lower LR for stable training\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"./ppo_auv_log/\"\n",
        ")\n",
        "\n",
        "# Callbacks: Model Evaluation & Checkpoints\n",
        "eval_callback = EvalCallback(\n",
        "    vec_env,\n",
        "    best_model_save_path=\"./ppo_auv_best_model/\",\n",
        "    log_path=\"./ppo_auv_logs/\",\n",
        "    eval_freq=5000,\n",
        "    deterministic=True,\n",
        "    render=False\n",
        ")\n",
        "\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=25000,  # Save model every 25k steps\n",
        "    save_path=\"./ppo_auv_checkpoints/\",\n",
        "    name_prefix=\"rl_model\"\n",
        ")\n",
        "\n",
        "# Train Model\n",
        "model.learn(total_timesteps=100000, callback=[eval_callback, checkpoint_callback])\n",
        "\n",
        "# Save Final Model\n",
        "model.save(\"ppo_auv_navigation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7bi4b8M1dz6",
        "outputId": "52cac8a5-edf1-4123-f111-634d628f8bb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 1, Action: 0, Reward: 6.881793398498814\n",
            "Step: 2, Action: 0, Reward: 6.835815681157129\n",
            "Step: 3, Action: 0, Reward: 6.789009531147201\n",
            "Step: 4, Action: 0, Reward: 6.741360805677061\n",
            "Step: 5, Action: 0, Reward: 6.692855288967223\n",
            "Step: 6, Action: 0, Reward: 6.6434787051458954\n",
            "Step: 7, Action: 0, Reward: 6.593216732132987\n",
            "Step: 8, Action: 0, Reward: 6.542055016549426\n",
            "Step: 9, Action: 0, Reward: 6.489979189690018\n",
            "Step: 10, Action: 0, Reward: 6.436974884603188\n",
            "Step: 11, Action: 0, Reward: 6.383027754310575\n",
            "Step: 12, Action: 0, Reward: 6.328123491205417\n",
            "Step: 13, Action: 0, Reward: 6.272247847666534\n",
            "Step: 14, Action: 0, Reward: 6.2153866579159\n",
            "Step: 15, Action: 0, Reward: 6.157525861158035\n",
            "Step: 16, Action: 0, Reward: 6.098651526024099\n",
            "Step: 17, Action: 0, Reward: 6.0387498763485326\n",
            "Step: 18, Action: 0, Reward: 5.977807318300847\n",
            "Step: 19, Action: 0, Reward: 5.915810468888054\n",
            "Step: 20, Action: 0, Reward: 5.852746185844637\n",
            "Step: 21, Action: 0, Reward: 5.788601598914056\n",
            "Step: 22, Action: 0, Reward: 5.723364142529732\n",
            "Step: 23, Action: 0, Reward: 5.6570215898867104\n",
            "Step: 24, Action: 0, Reward: 5.589562088398168\n",
            "Step: 25, Action: 0, Reward: 5.5209741965154535\n",
            "Step: 26, Action: 0, Reward: 5.451246921888355\n",
            "Step: 27, Action: 0, Reward: 5.380369760829069\n",
            "Step: 28, Action: 0, Reward: 5.308332739037809\n",
            "Step: 29, Action: 0, Reward: 5.23512645353307\n",
            "Step: 30, Action: 0, Reward: 5.160742115726009\n",
            "Step: 31, Action: 2, Reward: 8.180097842340075\n",
            "Step: 32, Action: 0, Reward: 5.1283816469081955\n",
            "Step: 33, Action: 2, Reward: 8.18938538870782\n",
            "Step: 34, Action: 0, Reward: 5.094988949399948\n",
            "Step: 35, Action: 2, Reward: 8.19872570160527\n",
            "Step: 36, Action: 2, Reward: 8.163590324331693\n",
            "Step: 37, Action: 0, Reward: 5.105038170900116\n",
            "Step: 38, Action: 2, Reward: 8.172636046862323\n",
            "Step: 39, Action: 0, Reward: 5.0698145437714\n",
            "Step: 40, Action: 2, Reward: 8.18171039804227\n",
            "Step: 41, Action: 2, Reward: 8.144908525259353\n",
            "Step: 42, Action: 0, Reward: 5.079303355400953\n",
            "Step: 43, Action: 2, Reward: 8.153619369274878\n",
            "Step: 44, Action: 2, Reward: 8.115398327605732\n",
            "Step: 45, Action: 2, Reward: 8.076106357608381\n",
            "Step: 46, Action: 2, Reward: 8.035708556101469\n",
            "Step: 47, Action: 2, Reward: 7.994168884221011\n",
            "Step: 48, Action: 2, Reward: 7.951450143268914\n",
            "Step: 49, Action: 0, Reward: 5.2832510782135955\n",
            "Step: 50, Action: 2, Reward: 7.957744650063461\n",
            "Step: 51, Action: 2, Reward: 7.913223472510964\n",
            "Step: 52, Action: 2, Reward: 7.867406899428744\n",
            "Step: 53, Action: 0, Reward: 5.349040998952432\n",
            "Step: 54, Action: 2, Reward: 7.872364225159316\n",
            "Step: 55, Action: 0, Reward: 5.312321771235418\n",
            "Step: 56, Action: 2, Reward: 7.877170646955278\n",
            "Step: 57, Action: 0, Reward: 5.274151455121654\n",
            "Step: 58, Action: 2, Reward: 7.881801619246858\n",
            "Step: 59, Action: 0, Reward: 5.234449502379164\n",
            "Step: 60, Action: 2, Reward: 7.886229822592696\n",
            "Step: 61, Action: 0, Reward: 5.1931297937983345\n",
            "Step: 62, Action: 2, Reward: 7.890424846301016\n",
            "Step: 63, Action: 0, Reward: 5.150100196021015\n",
            "Step: 64, Action: 2, Reward: 7.894352832751679\n",
            "Step: 65, Action: 2, Reward: 7.842682314634004\n",
            "Step: 66, Action: 0, Reward: 5.1605558449792\n",
            "Step: 67, Action: 2, Reward: 7.845447116402795\n",
            "Step: 68, Action: 2, Reward: 7.791173016458828\n",
            "Step: 69, Action: 2, Reward: 7.735088508146362\n",
            "Step: 70, Action: 2, Reward: 7.6771260942469155\n",
            "Step: 71, Action: 2, Reward: 7.617216032195415\n",
            "Step: 72, Action: 2, Reward: 7.555286324458734\n",
            "Step: 73, Action: 2, Reward: 7.491262719518232\n",
            "Step: 74, Action: 2, Reward: 7.425068725085993\n",
            "Step: 75, Action: 2, Reward: 7.356625635338219\n",
            "Step: 76, Action: 2, Reward: 7.28585257412135\n",
            "Step: 77, Action: 2, Reward: 7.21266655624504\n",
            "Step: 78, Action: 2, Reward: 7.136982569165724\n",
            "Step: 79, Action: 2, Reward: 7.0587136775193215\n",
            "Step: 80, Action: 2, Reward: 6.977771153144445\n",
            "Step: 81, Action: 2, Reward: 6.894064633390613\n",
            "Step: 82, Action: 0, Reward: 5.98327652871653\n",
            "Step: 83, Action: 2, Reward: 6.875364906101282\n",
            "Step: 84, Action: 0, Reward: 5.9444628551231204\n",
            "Step: 85, Action: 2, Reward: 6.855174446286654\n",
            "Step: 86, Action: 0, Reward: 5.903335819271263\n",
            "Step: 87, Action: 2, Reward: 6.833354461919612\n",
            "Step: 88, Action: 2, Reward: 6.739481362318287\n",
            "Step: 89, Action: 0, Reward: 5.929981850942667\n",
            "Step: 90, Action: 0, Reward: 5.813390269711434\n",
            "Step: 91, Action: 2, Reward: 6.784194666558392\n",
            "Step: 92, Action: 0, Reward: 5.764150795739553\n",
            "Step: 93, Action: 0, Reward: 5.640010744564705\n",
            "Step: 94, Action: 2, Reward: 6.828237256930549\n",
            "Step: 95, Action: 0, Reward: 5.583535256743559\n",
            "Step: 96, Action: 0, Reward: 5.451188781002756\n",
            "Step: 97, Action: 2, Reward: 6.871048143580154\n",
            "Step: 98, Action: 0, Reward: 5.386539790468703\n",
            "Step: 99, Action: 2, Reward: 6.839555028770903\n",
            "Step: 100, Action: 2, Reward: 6.7318677447180875\n",
            "Step: 101, Action: 0, Reward: 5.3908717870832135\n",
            "Step: 102, Action: 2, Reward: 6.6937244135649365\n",
            "Step: 103, Action: 0, Reward: 5.317777346993182\n",
            "Step: 104, Action: 2, Reward: 6.652042882304698\n",
            "Step: 105, Action: 2, Reward: 6.531793045564669\n",
            "Step: 106, Action: 0, Reward: 5.314259320151606\n",
            "Step: 107, Action: 2, Reward: 6.4817243468334595\n",
            "Step: 108, Action: 2, Reward: 6.351552908890881\n",
            "Step: 109, Action: 2, Reward: 6.215735469133321\n",
            "Step: 110, Action: 0, Reward: 5.382173654833267\n",
            "Step: 111, Action: 2, Reward: 6.150486350793898\n",
            "Step: 112, Action: 0, Reward: 5.292389238596584\n",
            "Step: 113, Action: 2, Reward: 6.079347212411932\n",
            "Step: 114, Action: 0, Reward: 5.195552374098469\n",
            "Step: 115, Action: 2, Reward: 6.001712111945565\n",
            "Step: 116, Action: 0, Reward: 5.091011312245115\n",
            "Step: 117, Action: 2, Reward: 5.916913586310599\n",
            "Step: 118, Action: 0, Reward: 4.978057767969233\n",
            "Step: 119, Action: 2, Reward: 5.824218866954993\n",
            "Step: 120, Action: 0, Reward: 4.855925638662271\n",
            "Step: 121, Action: 0, Reward: 4.651482698155647\n",
            "Step: 122, Action: 0, Reward: 4.439317878575011\n",
            "Step: 123, Action: 0, Reward: 4.219416683229866\n",
            "Step: 124, Action: 0, Reward: 3.991809991224642\n",
            "Step: 125, Action: 0, Reward: 3.756578729379285\n",
            "Step: 126, Action: 0, Reward: 3.5138582258323936\n",
            "Step: 127, Action: 0, Reward: 3.2638420735535334\n",
            "Step: 128, Action: 0, Reward: 3.006785320729435\n",
            "Step: 129, Action: 0, Reward: 2.743006801067409\n",
            "Step: 130, Action: 2, Reward: 6.289881775684805\n",
            "Step: 131, Action: 0, Reward: 2.5191581580897804\n",
            "Step: 132, Action: 2, Reward: 6.154726279432197\n",
            "Step: 133, Action: 2, Reward: 5.962965079607017\n",
            "Step: 134, Action: 0, Reward: 2.32287607748475\n",
            "Step: 135, Action: 2, Reward: 5.802778864281954\n",
            "Step: 136, Action: 0, Reward: 2.064283449121973\n",
            "Step: 137, Action: 2, Reward: 5.6263963810554785\n",
            "Step: 138, Action: 0, Reward: 1.789631227557571\n",
            "Step: 139, Action: 2, Reward: 5.432730055043038\n",
            "Step: 140, Action: 2, Reward: 5.194349710867421\n",
            "Step: 141, Action: 0, Reward: 1.5252097637375783\n",
            "Step: 142, Action: 0, Reward: 1.1917615961863248\n",
            "Step: 143, Action: 0, Reward: 0.8542338710077502\n",
            "Step: 144, Action: 0, Reward: 0.5137410077526994\n",
            "Step: 145, Action: 0, Reward: 0.17144817403142554\n",
            "Step: 146, Action: 0, Reward: -0.17144817403142554\n",
            "Step: 147, Action: 0, Reward: -0.5137410077526994\n",
            "Step: 148, Action: 2, Reward: 5.0046515971477135\n",
            "Step: 149, Action: 0, Reward: -0.8690734908572395\n",
            "Step: 150, Action: 2, Reward: 4.724659511663596\n",
            "Step: 151, Action: 0, Reward: -1.2324431090590693\n",
            "Step: 152, Action: 0, Reward: -1.5767710099295584\n",
            "Step: 153, Action: 2, Reward: 4.4017043529762745\n",
            "Step: 154, Action: 0, Reward: -1.945163110114727\n",
            "Step: 155, Action: 0, Reward: -2.2817737392796644\n",
            "Step: 156, Action: 0, Reward: -2.610400871734413\n",
            "Step: 157, Action: 0, Reward: -2.9302009490287872\n",
            "Step: 158, Action: 2, Reward: 3.971517851296902\n",
            "Step: 159, Action: 0, Reward: -3.2847145540116074\n",
            "Step: 160, Action: 2, Reward: 3.632659118078294\n",
            "Step: 161, Action: 0, Reward: 0.0\n",
            "Step: 162, Action: 0, Reward: 0.0\n",
            "Step: 163, Action: 0, Reward: 0.0\n",
            "Step: 164, Action: 4, Reward: 8.660366783219047\n",
            "Step: 165, Action: 4, Reward: 8.567765543682384\n",
            "Step: 166, Action: 2, Reward: 3.541748110515428\n",
            "Step: 167, Action: 4, Reward: 8.58231272493203\n",
            "Step: 168, Action: 4, Reward: 8.476660897754016\n",
            "Step: 169, Action: 4, Reward: 8.359862402919518\n",
            "Step: 170, Action: 4, Reward: 8.230481327422687\n",
            "Step: 171, Action: 4, Reward: 8.08688399401401\n",
            "Step: 172, Action: 4, Reward: 7.9272166556543056\n",
            "Step: 173, Action: 4, Reward: 7.749384283119269\n",
            "Step: 174, Action: 4, Reward: 7.551032807569875\n",
            "Step: 175, Action: 4, Reward: 7.329538406622866\n",
            "Step: 176, Action: 4, Reward: 7.082009050778915\n",
            "Step: 177, Action: 4, Reward: 6.805305565497619\n",
            "Step: 178, Action: 2, Reward: 4.778276025357009\n",
            "Step: 179, Action: 4, Reward: 6.6798575865011145\n",
            "Step: 180, Action: 4, Reward: 6.338662068622121\n",
            "Step: 181, Action: 4, Reward: 5.95600966773393\n",
            "Step: 182, Action: 4, Reward: 5.52806971957029\n",
            "Step: 183, Action: 4, Reward: 5.05149351215076\n",
            "Step: 184, Action: 4, Reward: 4.5238389559547265\n",
            "Step: 185, Action: 4, Reward: 3.9440853886343064\n",
            "Step: 186, Action: 4, Reward: 3.3131921986878154\n",
            "Step: 187, Action: 4, Reward: 2.634614270328335\n",
            "Step: 188, Action: 4, Reward: 1.914650411501846\n",
            "Step: 189, Action: 4, Reward: 1.162488181505914\n",
            "Step: 190, Action: 4, Reward: 0.3898410379943229\n",
            "Step: 191, Action: 4, Reward: -0.3898410379943229\n",
            "Step: 192, Action: 4, Reward: -1.162488181505914\n",
            "Step: 193, Action: 4, Reward: -1.914650411501846\n",
            "Step: 194, Action: 4, Reward: -2.634614270328335\n",
            "Step: 195, Action: 4, Reward: -3.3131921986878154\n",
            "Step: 196, Action: 4, Reward: -3.9440853886343064\n",
            "Step: 197, Action: 4, Reward: -4.5238389559547265\n",
            "Step: 198, Action: 4, Reward: -5.05149351215076\n",
            "Step: 199, Action: 4, Reward: -5.52806971957029\n",
            "Step: 200, Action: 4, Reward: -5.95600966773393\n",
            "Episode Finished\n"
          ]
        }
      ],
      "source": [
        "# Load the trained model\n",
        "model = PPO.load(\"ppo_auv_navigation\")\n",
        "\n",
        "# Evaluate the agent in the environment\n",
        "env = AUVNavigationEnv()\n",
        "obs, _ = env.reset()\n",
        "\n",
        "p_action = []\n",
        "\n",
        "for step in range(200):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = env.step(int(action))\n",
        "    p_action.append(int(reward))\n",
        "    print(f\"Step: {step+1}, Action: {action}, Reward: {reward}\")\n",
        "    #env.render()\n",
        "\n",
        "    if done:\n",
        "        print(\"Episode Finished\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lcwchb__kZ76",
        "outputId": "c291c340-b202-4bcc-c0b0-a6fed2d01ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Logging to ./dqn_auv_log/DQN_1\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -2.27    |\n",
            "|    exploration_rate | 0.924    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 4857     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 800      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 17.4     |\n",
            "|    exploration_rate | 0.848    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3584     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1600     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 19.6     |\n",
            "|    exploration_rate | 0.772    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 3709     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2400     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 16.1     |\n",
            "|    exploration_rate | 0.696    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 3971     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 3200     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 7.1      |\n",
            "|    exploration_rate | 0.62     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 4125     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 4000     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 9.1      |\n",
            "|    exploration_rate | 0.544    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 4178     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4800     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=5000, episode_reward=-71.17 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 200      |\n",
            "|    mean_reward      | -71.2    |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.525    |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 5000     |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 8.38     |\n",
            "|    exploration_rate | 0.468    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 2687     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 5600     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 0.204    |\n",
            "|    exploration_rate | 0.392    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 2845     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 6400     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 1.54     |\n",
            "|    exploration_rate | 0.316    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 2946     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 7200     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 4.26     |\n",
            "|    exploration_rate | 0.24     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 2990     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8000     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 2.84     |\n",
            "|    exploration_rate | 0.164    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 3091     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8800     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 4.39     |\n",
            "|    exploration_rate | 0.088    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 3158     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 9600     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-71.17 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 200      |\n",
            "|    mean_reward      | -71.2    |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.0501   |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 10000    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 27       |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 2318     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 10400    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.959    |\n",
            "|    n_updates        | 99       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 51.4     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1966     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 11200    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 299      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 94.5     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1675     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 12000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0882   |\n",
            "|    n_updates        | 499      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 144      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1472     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 12800    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.454    |\n",
            "|    n_updates        | 699      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 190      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1377     |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 13600    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.363    |\n",
            "|    n_updates        | 899      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 234      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1300     |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 14400    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.403    |\n",
            "|    n_updates        | 1099     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=976.18 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 200      |\n",
            "|    mean_reward      | 976      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 15000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.255    |\n",
            "|    n_updates        | 1249     |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 273      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1170     |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 15200    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.504    |\n",
            "|    n_updates        | 1299     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 309      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1128     |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 16000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.235    |\n",
            "|    n_updates        | 1499     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 344      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1094     |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 16800    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.253    |\n",
            "|    n_updates        | 1699     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 379      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1064     |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 17583    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.32     |\n",
            "|    n_updates        | 1895     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 410      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1038     |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 18333    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.417    |\n",
            "|    n_updates        | 2083     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 437      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1009     |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 19133    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.686    |\n",
            "|    n_updates        | 2283     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 460      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 971      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 19933    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.56     |\n",
            "|    n_updates        | 2483     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=1012.72 +/- 0.00\n",
            "Episode length: 200.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 200      |\n",
            "|    mean_reward      | 1.01e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 20000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.68     |\n",
            "|    n_updates        | 2499     |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 502      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 916      |\n",
            "|    time_elapsed     | 22       |\n",
            "|    total_timesteps  | 20800    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.139    |\n",
            "|    n_updates        | 2699     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 542      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 904      |\n",
            "|    time_elapsed     | 23       |\n",
            "|    total_timesteps  | 21600    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.173    |\n",
            "|    n_updates        | 2899     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 582      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 893      |\n",
            "|    time_elapsed     | 25       |\n",
            "|    total_timesteps  | 22400    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.452    |\n",
            "|    n_updates        | 3099     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 624      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 883      |\n",
            "|    time_elapsed     | 26       |\n",
            "|    total_timesteps  | 23200    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.43     |\n",
            "|    n_updates        | 3299     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 670      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 873      |\n",
            "|    time_elapsed     | 27       |\n",
            "|    total_timesteps  | 23953    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.147    |\n",
            "|    n_updates        | 3488     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 198      |\n",
            "|    ep_rew_mean      | 713      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 866      |\n",
            "|    time_elapsed     | 28       |\n",
            "|    total_timesteps  | 24689    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.421    |\n",
            "|    n_updates        | 3672     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=1113.94 +/- 0.00\n",
            "Episode length: 179.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 179      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 25000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.08     |\n",
            "|    n_updates        | 3749     |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 198      |\n",
            "|    ep_rew_mean      | 758      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 837      |\n",
            "|    time_elapsed     | 30       |\n",
            "|    total_timesteps  | 25555    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.13     |\n",
            "|    n_updates        | 3888     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | 804      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 826      |\n",
            "|    time_elapsed     | 31       |\n",
            "|    total_timesteps  | 26303    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.138    |\n",
            "|    n_updates        | 4075     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | 848      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 811      |\n",
            "|    time_elapsed     | 33       |\n",
            "|    total_timesteps  | 27068    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.996    |\n",
            "|    n_updates        | 4266     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | 892      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 806      |\n",
            "|    time_elapsed     | 34       |\n",
            "|    total_timesteps  | 27817    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.98     |\n",
            "|    n_updates        | 4454     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | 936      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 802      |\n",
            "|    time_elapsed     | 35       |\n",
            "|    total_timesteps  | 28567    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.243    |\n",
            "|    n_updates        | 4641     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | 980      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 797      |\n",
            "|    time_elapsed     | 36       |\n",
            "|    total_timesteps  | 29298    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.342    |\n",
            "|    n_updates        | 4824     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=1111.76 +/- 0.00\n",
            "Episode length: 177.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 177      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 30000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.04     |\n",
            "|    n_updates        | 4999     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | 1.01e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 781      |\n",
            "|    time_elapsed     | 38       |\n",
            "|    total_timesteps  | 30185    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.728    |\n",
            "|    n_updates        | 5046     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | 1.04e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 778      |\n",
            "|    time_elapsed     | 39       |\n",
            "|    total_timesteps  | 30940    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.34     |\n",
            "|    n_updates        | 5234     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | 1.06e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 774      |\n",
            "|    time_elapsed     | 40       |\n",
            "|    total_timesteps  | 31672    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.14     |\n",
            "|    n_updates        | 5417     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | 1.07e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 771      |\n",
            "|    time_elapsed     | 41       |\n",
            "|    total_timesteps  | 32410    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.238    |\n",
            "|    n_updates        | 5602     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | 1.08e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 769      |\n",
            "|    time_elapsed     | 43       |\n",
            "|    total_timesteps  | 33163    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.287    |\n",
            "|    n_updates        | 5790     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | 1.08e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 763      |\n",
            "|    time_elapsed     | 44       |\n",
            "|    total_timesteps  | 33900    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.182    |\n",
            "|    n_updates        | 5974     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | 1.09e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 754      |\n",
            "|    time_elapsed     | 45       |\n",
            "|    total_timesteps  | 34654    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.103    |\n",
            "|    n_updates        | 6163     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=35000, episode_reward=1115.07 +/- 0.00\n",
            "Episode length: 180.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 180      |\n",
            "|    mean_reward      | 1.12e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 35000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0942   |\n",
            "|    n_updates        | 6249     |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | 1.09e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 741      |\n",
            "|    time_elapsed     | 47       |\n",
            "|    total_timesteps  | 35580    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.25     |\n",
            "|    n_updates        | 6394     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | 1.09e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 740      |\n",
            "|    time_elapsed     | 49       |\n",
            "|    total_timesteps  | 36336    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.276    |\n",
            "|    n_updates        | 6583     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | 1.09e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 737      |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 37085    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.11     |\n",
            "|    n_updates        | 6771     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | 1.09e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 736      |\n",
            "|    time_elapsed     | 51       |\n",
            "|    total_timesteps  | 37847    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.163    |\n",
            "|    n_updates        | 6961     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | 1.1e+03  |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 734      |\n",
            "|    time_elapsed     | 52       |\n",
            "|    total_timesteps  | 38587    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.65     |\n",
            "|    n_updates        | 7146     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 189      |\n",
            "|    ep_rew_mean      | 1.1e+03  |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 733      |\n",
            "|    time_elapsed     | 53       |\n",
            "|    total_timesteps  | 39347    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.182    |\n",
            "|    n_updates        | 7336     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=1109.67 +/- 0.00\n",
            "Episode length: 177.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 177      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 40000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.207    |\n",
            "|    n_updates        | 7499     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 189      |\n",
            "|    ep_rew_mean      | 1.1e+03  |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 55       |\n",
            "|    total_timesteps  | 40183    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 7545     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 718      |\n",
            "|    time_elapsed     | 56       |\n",
            "|    total_timesteps  | 40921    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.124    |\n",
            "|    n_updates        | 7730     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 712      |\n",
            "|    time_elapsed     | 58       |\n",
            "|    total_timesteps  | 41690    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.105    |\n",
            "|    n_updates        | 7922     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 711      |\n",
            "|    time_elapsed     | 59       |\n",
            "|    total_timesteps  | 42436    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.134    |\n",
            "|    n_updates        | 8108     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 710      |\n",
            "|    time_elapsed     | 60       |\n",
            "|    total_timesteps  | 43180    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.69     |\n",
            "|    n_updates        | 8294     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 709      |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 43928    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.246    |\n",
            "|    n_updates        | 8481     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 708      |\n",
            "|    time_elapsed     | 63       |\n",
            "|    total_timesteps  | 44676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0835   |\n",
            "|    n_updates        | 8668     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=45000, episode_reward=1112.84 +/- 0.00\n",
            "Episode length: 178.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 178      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 45000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.156    |\n",
            "|    n_updates        | 8749     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 701      |\n",
            "|    time_elapsed     | 64       |\n",
            "|    total_timesteps  | 45563    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0691   |\n",
            "|    n_updates        | 8890     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 700      |\n",
            "|    time_elapsed     | 66       |\n",
            "|    total_timesteps  | 46306    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.09     |\n",
            "|    n_updates        | 9076     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 699      |\n",
            "|    time_elapsed     | 67       |\n",
            "|    total_timesteps  | 47054    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.99     |\n",
            "|    n_updates        | 9263     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 699      |\n",
            "|    time_elapsed     | 68       |\n",
            "|    total_timesteps  | 47800    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.97     |\n",
            "|    n_updates        | 9449     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 695      |\n",
            "|    time_elapsed     | 69       |\n",
            "|    total_timesteps  | 48552    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.114    |\n",
            "|    n_updates        | 9637     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 692      |\n",
            "|    time_elapsed     | 71       |\n",
            "|    total_timesteps  | 49303    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.127    |\n",
            "|    n_updates        | 9825     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=1112.84 +/- 0.00\n",
            "Episode length: 178.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 178      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 50000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.15     |\n",
            "|    n_updates        | 9999     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 73       |\n",
            "|    total_timesteps  | 50193    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.229    |\n",
            "|    n_updates        | 10048    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 74       |\n",
            "|    total_timesteps  | 50933    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.53     |\n",
            "|    n_updates        | 10233    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 75       |\n",
            "|    total_timesteps  | 51677    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.92     |\n",
            "|    n_updates        | 10419    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 76       |\n",
            "|    total_timesteps  | 52413    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.295    |\n",
            "|    n_updates        | 10603    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 77       |\n",
            "|    total_timesteps  | 53167    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.125    |\n",
            "|    n_updates        | 10791    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 78       |\n",
            "|    total_timesteps  | 53909    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 10977    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 79       |\n",
            "|    total_timesteps  | 54653    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0887   |\n",
            "|    n_updates        | 11163    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=55000, episode_reward=1115.07 +/- 0.00\n",
            "Episode length: 178.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 178      |\n",
            "|    mean_reward      | 1.12e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 55000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0668   |\n",
            "|    n_updates        | 11249    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 677      |\n",
            "|    time_elapsed     | 81       |\n",
            "|    total_timesteps  | 55562    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0966   |\n",
            "|    n_updates        | 11390    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 674      |\n",
            "|    time_elapsed     | 83       |\n",
            "|    total_timesteps  | 56318    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.112    |\n",
            "|    n_updates        | 11579    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 674      |\n",
            "|    time_elapsed     | 84       |\n",
            "|    total_timesteps  | 57070    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.73     |\n",
            "|    n_updates        | 11767    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 674      |\n",
            "|    time_elapsed     | 85       |\n",
            "|    total_timesteps  | 57807    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0907   |\n",
            "|    n_updates        | 11951    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 674      |\n",
            "|    time_elapsed     | 86       |\n",
            "|    total_timesteps  | 58540    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.1      |\n",
            "|    n_updates        | 12134    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 674      |\n",
            "|    time_elapsed     | 87       |\n",
            "|    total_timesteps  | 59292    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0995   |\n",
            "|    n_updates        | 12322    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=1112.84 +/- 0.00\n",
            "Episode length: 178.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 178      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 60000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0722   |\n",
            "|    n_updates        | 12499    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 670      |\n",
            "|    time_elapsed     | 89       |\n",
            "|    total_timesteps  | 60191    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.18     |\n",
            "|    n_updates        | 12547    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 669      |\n",
            "|    time_elapsed     | 90       |\n",
            "|    total_timesteps  | 60934    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.13     |\n",
            "|    n_updates        | 12733    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 669      |\n",
            "|    time_elapsed     | 92       |\n",
            "|    total_timesteps  | 61695    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0833   |\n",
            "|    n_updates        | 12923    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 669      |\n",
            "|    time_elapsed     | 93       |\n",
            "|    total_timesteps  | 62447    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.102    |\n",
            "|    n_updates        | 13111    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 667      |\n",
            "|    time_elapsed     | 94       |\n",
            "|    total_timesteps  | 63189    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.105    |\n",
            "|    n_updates        | 13297    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 665      |\n",
            "|    time_elapsed     | 96       |\n",
            "|    total_timesteps  | 63946    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.111    |\n",
            "|    n_updates        | 13486    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 665      |\n",
            "|    time_elapsed     | 97       |\n",
            "|    total_timesteps  | 64681    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.143    |\n",
            "|    n_updates        | 13670    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=65000, episode_reward=1115.07 +/- 0.00\n",
            "Episode length: 178.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 178      |\n",
            "|    mean_reward      | 1.12e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 65000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.37     |\n",
            "|    n_updates        | 13749    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 660      |\n",
            "|    time_elapsed     | 99       |\n",
            "|    total_timesteps  | 65565    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.076    |\n",
            "|    n_updates        | 13891    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 660      |\n",
            "|    time_elapsed     | 100      |\n",
            "|    total_timesteps  | 66309    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.118    |\n",
            "|    n_updates        | 14077    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 661      |\n",
            "|    time_elapsed     | 101      |\n",
            "|    total_timesteps  | 67064    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.11     |\n",
            "|    n_updates        | 14265    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 660      |\n",
            "|    time_elapsed     | 102      |\n",
            "|    total_timesteps  | 67806    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0301   |\n",
            "|    n_updates        | 14451    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 661      |\n",
            "|    time_elapsed     | 103      |\n",
            "|    total_timesteps  | 68546    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.31     |\n",
            "|    n_updates        | 14636    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 186      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 661      |\n",
            "|    time_elapsed     | 104      |\n",
            "|    total_timesteps  | 69282    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0289   |\n",
            "|    n_updates        | 14820    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=1116.24 +/- 0.00\n",
            "Episode length: 179.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 179      |\n",
            "|    mean_reward      | 1.12e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 70000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.49     |\n",
            "|    n_updates        | 14999    |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 655      |\n",
            "|    time_elapsed     | 107      |\n",
            "|    total_timesteps  | 70183    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0986   |\n",
            "|    n_updates        | 15045    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 653      |\n",
            "|    time_elapsed     | 108      |\n",
            "|    total_timesteps  | 70934    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0637   |\n",
            "|    n_updates        | 15233    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 653      |\n",
            "|    time_elapsed     | 109      |\n",
            "|    total_timesteps  | 71687    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0603   |\n",
            "|    n_updates        | 15421    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 653      |\n",
            "|    time_elapsed     | 110      |\n",
            "|    total_timesteps  | 72439    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.56     |\n",
            "|    n_updates        | 15609    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 653      |\n",
            "|    time_elapsed     | 111      |\n",
            "|    total_timesteps  | 73193    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.65     |\n",
            "|    n_updates        | 15798    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 653      |\n",
            "|    time_elapsed     | 113      |\n",
            "|    total_timesteps  | 73937    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.52     |\n",
            "|    n_updates        | 15984    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 653      |\n",
            "|    time_elapsed     | 114      |\n",
            "|    total_timesteps  | 74676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.56     |\n",
            "|    n_updates        | 16168    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=75000, episode_reward=1112.84 +/- 0.00\n",
            "Episode length: 178.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 178      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 75000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0392   |\n",
            "|    n_updates        | 16249    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 650      |\n",
            "|    time_elapsed     | 116      |\n",
            "|    total_timesteps  | 75549    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0747   |\n",
            "|    n_updates        | 16387    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 650      |\n",
            "|    time_elapsed     | 117      |\n",
            "|    total_timesteps  | 76295    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0468   |\n",
            "|    n_updates        | 16573    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 650      |\n",
            "|    time_elapsed     | 118      |\n",
            "|    total_timesteps  | 77043    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.682    |\n",
            "|    n_updates        | 16760    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 648      |\n",
            "|    time_elapsed     | 119      |\n",
            "|    total_timesteps  | 77801    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.48     |\n",
            "|    n_updates        | 16950    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 647      |\n",
            "|    time_elapsed     | 121      |\n",
            "|    total_timesteps  | 78557    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.22     |\n",
            "|    n_updates        | 17139    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 647      |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 79293    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.33     |\n",
            "|    n_updates        | 17323    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=1109.67 +/- 0.00\n",
            "Episode length: 177.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 177      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 80000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0438   |\n",
            "|    n_updates        | 17499    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 644      |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 80189    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0755   |\n",
            "|    n_updates        | 17547    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 644      |\n",
            "|    time_elapsed     | 125      |\n",
            "|    total_timesteps  | 80956    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.03     |\n",
            "|    n_updates        | 17738    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 644      |\n",
            "|    time_elapsed     | 126      |\n",
            "|    total_timesteps  | 81702    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0415   |\n",
            "|    n_updates        | 17925    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 644      |\n",
            "|    time_elapsed     | 127      |\n",
            "|    total_timesteps  | 82438    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.053    |\n",
            "|    n_updates        | 18109    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 645      |\n",
            "|    time_elapsed     | 128      |\n",
            "|    total_timesteps  | 83182    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.61     |\n",
            "|    n_updates        | 18295    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 645      |\n",
            "|    time_elapsed     | 130      |\n",
            "|    total_timesteps  | 83926    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0328   |\n",
            "|    n_updates        | 18481    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 644      |\n",
            "|    time_elapsed     | 131      |\n",
            "|    total_timesteps  | 84684    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.87     |\n",
            "|    n_updates        | 18670    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=85000, episode_reward=1111.76 +/- 0.00\n",
            "Episode length: 177.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 177      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 85000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.56     |\n",
            "|    n_updates        | 18749    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 639      |\n",
            "|    time_elapsed     | 133      |\n",
            "|    total_timesteps  | 85555    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0126   |\n",
            "|    n_updates        | 18888    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 639      |\n",
            "|    time_elapsed     | 134      |\n",
            "|    total_timesteps  | 86287    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0486   |\n",
            "|    n_updates        | 19071    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 639      |\n",
            "|    time_elapsed     | 136      |\n",
            "|    total_timesteps  | 87041    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.734    |\n",
            "|    n_updates        | 19260    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 639      |\n",
            "|    time_elapsed     | 137      |\n",
            "|    total_timesteps  | 87781    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0333   |\n",
            "|    n_updates        | 19445    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 639      |\n",
            "|    time_elapsed     | 138      |\n",
            "|    total_timesteps  | 88539    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0322   |\n",
            "|    n_updates        | 19634    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 640      |\n",
            "|    time_elapsed     | 139      |\n",
            "|    total_timesteps  | 89297    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0343   |\n",
            "|    n_updates        | 19824    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=1109.67 +/- 0.00\n",
            "Episode length: 177.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 177      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 90000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.02     |\n",
            "|    n_updates        | 19999    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 637      |\n",
            "|    time_elapsed     | 141      |\n",
            "|    total_timesteps  | 90183    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0301   |\n",
            "|    n_updates        | 20045    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 637      |\n",
            "|    time_elapsed     | 142      |\n",
            "|    total_timesteps  | 90953    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0338   |\n",
            "|    n_updates        | 20238    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 637      |\n",
            "|    time_elapsed     | 143      |\n",
            "|    total_timesteps  | 91693    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0242   |\n",
            "|    n_updates        | 20423    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 636      |\n",
            "|    time_elapsed     | 145      |\n",
            "|    total_timesteps  | 92437    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0243   |\n",
            "|    n_updates        | 20609    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 635      |\n",
            "|    time_elapsed     | 146      |\n",
            "|    total_timesteps  | 93183    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0755   |\n",
            "|    n_updates        | 20795    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 635      |\n",
            "|    time_elapsed     | 147      |\n",
            "|    total_timesteps  | 93941    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0251   |\n",
            "|    n_updates        | 20985    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 636      |\n",
            "|    time_elapsed     | 148      |\n",
            "|    total_timesteps  | 94693    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.078    |\n",
            "|    n_updates        | 21173    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=95000, episode_reward=1111.76 +/- 0.00\n",
            "Episode length: 177.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 177      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 95000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0343   |\n",
            "|    n_updates        | 21249    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 633      |\n",
            "|    time_elapsed     | 150      |\n",
            "|    total_timesteps  | 95565    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.12     |\n",
            "|    n_updates        | 21391    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 633      |\n",
            "|    time_elapsed     | 151      |\n",
            "|    total_timesteps  | 96320    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.87     |\n",
            "|    n_updates        | 21579    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 634      |\n",
            "|    time_elapsed     | 153      |\n",
            "|    total_timesteps  | 97078    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.127    |\n",
            "|    n_updates        | 21769    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 634      |\n",
            "|    time_elapsed     | 154      |\n",
            "|    total_timesteps  | 97828    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.99     |\n",
            "|    n_updates        | 21956    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 634      |\n",
            "|    time_elapsed     | 155      |\n",
            "|    total_timesteps  | 98566    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0495   |\n",
            "|    n_updates        | 22141    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 1.11e+03 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 633      |\n",
            "|    time_elapsed     | 156      |\n",
            "|    total_timesteps  | 99326    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0248   |\n",
            "|    n_updates        | 22331    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=1111.76 +/- 0.00\n",
            "Episode length: 177.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 177      |\n",
            "|    mean_reward      | 1.11e+03 |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 100000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0241   |\n",
            "|    n_updates        | 22499    |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# Initialize environment\n",
        "env = AUVNavigationEnv()\n",
        "env = Monitor(env)  # Wrap for logging\n",
        "vec_env = DummyVecEnv([lambda: env])  # Vectorized environment\n",
        "\n",
        "# DQN Model with Hyperparameters\n",
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    vec_env,\n",
        "    buffer_size=50000,  # Larger replay buffer\n",
        "    learning_starts=10000,  # Start learning after 10k steps\n",
        "    batch_size=64,  # Mini-batch size\n",
        "    tau=1.0,  # Soft update factor for target network\n",
        "    gamma=0.99,  # Discount factor\n",
        "    learning_rate=1e-4,  # Lower learning rate for stability\n",
        "    exploration_fraction=0.1,  # Fraction of exploration phase\n",
        "    exploration_final_eps=0.05,  # Minimum exploration rate\n",
        "    train_freq=4,  # Train every 4 steps\n",
        "    target_update_interval=1000,  # Update target network every 1k steps\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"./dqn_auv_log/\"\n",
        ")\n",
        "\n",
        "# Callbacks: Model Evaluation & Checkpoints\n",
        "eval_callback = EvalCallback(\n",
        "    vec_env,\n",
        "    best_model_save_path=\"./dqn_auv_best_model/\",\n",
        "    log_path=\"./dqn_auv_logs/\",\n",
        "    eval_freq=5000,\n",
        "    deterministic=True,\n",
        "    render=False\n",
        ")\n",
        "\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=25000,  # Save model every 25k steps\n",
        "    save_path=\"./dqn_auv_checkpoints/\",\n",
        "    name_prefix=\"rl_model\"\n",
        ")\n",
        "\n",
        "# Train Model\n",
        "model.learn(total_timesteps=100000, callback=[eval_callback, checkpoint_callback])\n",
        "\n",
        "# Save Final Model\n",
        "model.save(\"dqn_auv_navigation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AylZgytMk35N",
        "outputId": "f5ba5b64-b763-4700-91ec-dc50f4f6de1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 1, Action: 2, Reward: 6.881793398498814\n",
            "Step: 2, Action: 2, Reward: 6.835815681157129\n",
            "Step: 3, Action: 2, Reward: 6.789009531147201\n",
            "Step: 4, Action: 2, Reward: 6.741360805677061\n",
            "Step: 5, Action: 2, Reward: 6.692855288967223\n",
            "Step: 6, Action: 2, Reward: 6.6434787051458954\n",
            "Step: 7, Action: 2, Reward: 6.593216732132987\n",
            "Step: 8, Action: 2, Reward: 6.542055016549426\n",
            "Step: 9, Action: 2, Reward: 6.489979189690018\n",
            "Step: 10, Action: 2, Reward: 6.436974884603188\n",
            "Step: 11, Action: 2, Reward: 6.383027754310575\n",
            "Step: 12, Action: 2, Reward: 6.328123491205417\n",
            "Step: 13, Action: 2, Reward: 6.272247847666534\n",
            "Step: 14, Action: 2, Reward: 6.2153866579159\n",
            "Step: 15, Action: 2, Reward: 6.157525861158035\n",
            "Step: 16, Action: 2, Reward: 6.098651526024099\n",
            "Step: 17, Action: 2, Reward: 6.0387498763485326\n",
            "Step: 18, Action: 2, Reward: 5.977807318300847\n",
            "Step: 19, Action: 2, Reward: 5.915810468888054\n",
            "Step: 20, Action: 2, Reward: 5.852746185844637\n",
            "Step: 21, Action: 2, Reward: 5.788601598914056\n",
            "Step: 22, Action: 2, Reward: 5.723364142529732\n",
            "Step: 23, Action: 0, Reward: 7.829815983748745\n",
            "Step: 24, Action: 2, Reward: 5.701061552287854\n",
            "Step: 25, Action: 0, Reward: 7.835772769625748\n",
            "Step: 26, Action: 0, Reward: 7.796785408824007\n",
            "Step: 27, Action: 2, Reward: 5.723028762508022\n",
            "Step: 28, Action: 0, Reward: 7.802326274512126\n",
            "Step: 29, Action: 0, Reward: 7.761942328835687\n",
            "Step: 30, Action: 2, Reward: 5.7456933697180546\n",
            "Step: 31, Action: 0, Reward: 7.767014527471616\n",
            "Step: 32, Action: 0, Reward: 7.72514520201085\n",
            "Step: 33, Action: 0, Reward: 7.682243482694133\n",
            "Step: 34, Action: 2, Reward: 5.816526387264247\n",
            "Step: 35, Action: 0, Reward: 7.6862383719931415\n",
            "Step: 36, Action: 0, Reward: 7.641696582006716\n",
            "Step: 37, Action: 2, Reward: 5.841706377294145\n",
            "Step: 38, Action: 0, Reward: 7.645050381642733\n",
            "Step: 39, Action: 0, Reward: 7.598758792523057\n",
            "Step: 40, Action: 2, Reward: 5.867693323348675\n",
            "Step: 41, Action: 0, Reward: 7.6013920568379945\n",
            "Step: 42, Action: 0, Reward: 7.553230970099207\n",
            "Step: 43, Action: 2, Reward: 5.894511849141395\n",
            "Step: 44, Action: 0, Reward: 7.5550543261205405\n",
            "Step: 45, Action: 0, Reward: 7.504892971206516\n",
            "Step: 46, Action: 2, Reward: 5.922185304581262\n",
            "Step: 47, Action: 0, Reward: 7.505805736852267\n",
            "Step: 48, Action: 2, Reward: 5.897701565565825\n",
            "Step: 49, Action: 0, Reward: 7.506534600172756\n",
            "Step: 50, Action: 2, Reward: 5.872250061688646\n",
            "Step: 51, Action: 0, Reward: 7.507059827390918\n",
            "Step: 52, Action: 0, Reward: 7.453044594374063\n",
            "Step: 53, Action: 2, Reward: 5.9000917144113885\n",
            "Step: 54, Action: 0, Reward: 7.452442482866104\n",
            "Step: 55, Action: 2, Reward: 5.873191006752165\n",
            "Step: 56, Action: 0, Reward: 7.451557491898484\n",
            "Step: 57, Action: 2, Reward: 5.845155411050484\n",
            "Step: 58, Action: 0, Reward: 7.45036124075483\n",
            "Step: 59, Action: 2, Reward: 5.8159175665167595\n",
            "Step: 60, Action: 0, Reward: 7.448822481832735\n",
            "Step: 61, Action: 2, Reward: 5.785405081587243\n",
            "Step: 62, Action: 0, Reward: 7.446906784463749\n",
            "Step: 63, Action: 2, Reward: 5.753540092610336\n",
            "Step: 64, Action: 0, Reward: 7.4445761806804\n",
            "Step: 65, Action: 2, Reward: 5.720238779619109\n",
            "Step: 66, Action: 0, Reward: 7.441788768037725\n",
            "Step: 67, Action: 0, Reward: 7.378747070093397\n",
            "Step: 68, Action: 2, Reward: 5.745162028731414\n",
            "Step: 69, Action: 0, Reward: 7.374195420387792\n",
            "Step: 70, Action: 2, Reward: 5.709416964378988\n",
            "Step: 71, Action: 0, Reward: 7.3690328358783574\n",
            "Step: 72, Action: 2, Reward: 5.6719428732314725\n",
            "Step: 73, Action: 0, Reward: 7.363198626976271\n",
            "Step: 74, Action: 0, Reward: 7.293961323253626\n",
            "Step: 75, Action: 2, Reward: 5.695288571266985\n",
            "Step: 76, Action: 0, Reward: 7.28585257412135\n",
            "Step: 77, Action: 2, Reward: 5.654723026844124\n",
            "Step: 78, Action: 0, Reward: 7.2768548573822045\n",
            "Step: 79, Action: 0, Reward: 7.201954683426521\n",
            "Step: 80, Action: 2, Reward: 5.676971082139772\n",
            "Step: 81, Action: 0, Reward: 7.190177382830214\n",
            "Step: 82, Action: 2, Reward: 5.632759529559124\n",
            "Step: 83, Action: 0, Reward: 7.177229731364534\n",
            "Step: 84, Action: 2, Reward: 5.586110018747235\n",
            "Step: 85, Action: 0, Reward: 7.162995325466284\n",
            "Step: 86, Action: 2, Reward: 5.536841152328051\n",
            "Step: 87, Action: 0, Reward: 7.14734490900085\n",
            "Step: 88, Action: 0, Reward: 7.061521850140338\n",
            "Step: 89, Action: 2, Reward: 5.553368333196644\n",
            "Step: 90, Action: 0, Reward: 7.041931291932073\n",
            "Step: 91, Action: 2, Reward: 5.4989113130061185\n",
            "Step: 92, Action: 0, Reward: 7.0204800288540525\n",
            "Step: 93, Action: 2, Reward: 5.441150662564027\n",
            "Step: 94, Action: 0, Reward: 6.996977891481606\n",
            "Step: 95, Action: 2, Reward: 5.379822354787933\n",
            "Step: 96, Action: 0, Reward: 6.9712131663438015\n",
            "Step: 97, Action: 0, Reward: 6.871048143580154\n",
            "Step: 98, Action: 2, Reward: 5.386539790468703\n",
            "Step: 99, Action: 0, Reward: 6.839555028770903\n",
            "Step: 100, Action: 2, Reward: 5.317652739264815\n",
            "Step: 101, Action: 0, Reward: 6.8050867925364855\n",
            "Step: 102, Action: 0, Reward: 6.6937244135649365\n",
            "Step: 103, Action: 2, Reward: 5.317777346993182\n",
            "Step: 104, Action: 0, Reward: 6.652042882304698\n",
            "Step: 105, Action: 2, Reward: 5.239600317843056\n",
            "Step: 106, Action: 0, Reward: 6.606452047873219\n",
            "Step: 107, Action: 0, Reward: 6.4817243468334595\n",
            "Step: 108, Action: 2, Reward: 5.230712425254254\n",
            "Step: 109, Action: 0, Reward: 6.427014621443092\n",
            "Step: 110, Action: 2, Reward: 5.1410157049609495\n",
            "Step: 111, Action: 0, Reward: 6.367176151621479\n",
            "Step: 112, Action: 2, Reward: 5.044618918223165\n",
            "Step: 113, Action: 4, Reward: 5.822754970773616\n",
            "Step: 114, Action: 0, Reward: 6.390836086703899\n",
            "Step: 115, Action: 4, Reward: 5.751556726803813\n",
            "Step: 116, Action: 2, Reward: 5.084743021813267\n",
            "Step: 117, Action: 4, Reward: 5.656159317572644\n",
            "Step: 118, Action: 0, Reward: 6.509861171529323\n",
            "Step: 119, Action: 2, Reward: 5.052701737484355\n",
            "Step: 120, Action: 4, Reward: 5.6492549031342065\n",
            "Step: 121, Action: 0, Reward: 6.542311485070371\n",
            "Step: 122, Action: 2, Reward: 5.017555393400599\n",
            "Step: 123, Action: 4, Reward: 5.641540925612176\n",
            "Step: 124, Action: 2, Reward: 4.886742670824162\n",
            "Step: 125, Action: 4, Reward: 5.525556875342801\n",
            "Step: 126, Action: 0, Reward: 6.777133732444014\n",
            "Step: 127, Action: 2, Reward: 4.839476671572811\n",
            "Step: 128, Action: 4, Reward: 5.5097014892808716\n",
            "Step: 129, Action: 0, Reward: 6.826387500932469\n",
            "Step: 130, Action: 4, Reward: 5.40982995909296\n",
            "Step: 131, Action: 0, Reward: 6.7739292847571875\n",
            "Step: 132, Action: 2, Reward: 4.9756265549027745\n",
            "Step: 133, Action: 0, Reward: 6.706413650629379\n",
            "Step: 134, Action: 4, Reward: 5.507887563502898\n",
            "Step: 135, Action: 2, Reward: 4.92605120658812\n",
            "Step: 136, Action: 0, Reward: 6.758841798863422\n",
            "Step: 137, Action: 4, Reward: 5.488919505473788\n",
            "Step: 138, Action: 2, Reward: 4.869995801509539\n",
            "Step: 139, Action: 0, Reward: 6.817413141196482\n",
            "Step: 140, Action: 4, Reward: 5.4671251713514835\n",
            "Step: 141, Action: 2, Reward: 4.806120433631236\n",
            "Step: 142, Action: 0, Reward: 6.8832504548134565\n",
            "Step: 143, Action: 4, Reward: 5.441841151983127\n",
            "Step: 144, Action: 2, Reward: 4.732694617386635\n",
            "Step: 145, Action: 0, Reward: 6.957759399360839\n",
            "Step: 146, Action: 4, Reward: 5.412184700691931\n",
            "Step: 147, Action: 2, Reward: 4.647446460287554\n",
            "Step: 148, Action: 0, Reward: 7.042719472901844\n",
            "Step: 149, Action: 4, Reward: 5.376957457648395\n",
            "Step: 150, Action: 0, Reward: 6.981342252807359\n",
            "Step: 151, Action: 2, Reward: 4.706405134021345\n",
            "Step: 152, Action: 0, Reward: 6.885770590017799\n",
            "Step: 153, Action: 2, Reward: 4.464725620314454\n",
            "Step: 154, Action: 4, Reward: 5.666001313321196\n",
            "Step: 155, Action: 0, Reward: 6.983588161104137\n",
            "Step: 156, Action: 2, Reward: 4.326860061605551\n",
            "Step: 157, Action: 4, Reward: 5.6429741137684175\n",
            "Step: 158, Action: 0, Reward: 7.099658394919892\n",
            "Step: 159, Action: 0, Reward: 6.772286296517578\n",
            "Step: 160, Action: 4, Reward: 5.712313687766777\n",
            "Step: 161, Action: 2, Reward: 4.5238389559547265\n",
            "Step: 162, Action: 0, Reward: 6.885115766572412\n",
            "Step: 163, Action: 4, Reward: 5.695253203485837\n",
            "Step: 164, Action: 0, Reward: 6.775431109914241\n",
            "Step: 165, Action: 2, Reward: 4.59215491262972\n",
            "Step: 166, Action: 0, Reward: 6.568036180613124\n",
            "Step: 167, Action: 4, Reward: 6.024480247079023\n",
            "Step: 168, Action: 0, Reward: 6.392306799054115\n",
            "Step: 169, Action: 2, Reward: 4.680262821492445\n",
            "Step: 170, Action: 4, Reward: 6.058671322547369\n",
            "Step: 171, Action: 0, Reward: 6.509259827561618\n",
            "Step: 172, Action: 2, Reward: 4.42892656767353\n",
            "Step: 173, Action: 4, Reward: 6.100779360031323\n",
            "Step: 174, Action: 0, Reward: 6.67943574432627\n",
            "Step: 175, Action: 2, Reward: 4.031242374328485\n",
            "Step: 176, Action: 4, Reward: 6.148351928654963\n",
            "Step: 177, Action: 0, Reward: 6.94749047311074\n",
            "Episode Finished. Resetting Environment.\n",
            "Step: 178, Action: 2, Reward: 6.881793398498814\n",
            "Step: 179, Action: 2, Reward: 6.835815681157129\n",
            "Step: 180, Action: 2, Reward: 6.789009531147201\n",
            "Step: 181, Action: 2, Reward: 6.741360805677061\n",
            "Step: 182, Action: 2, Reward: 6.692855288967223\n",
            "Step: 183, Action: 2, Reward: 6.6434787051458954\n",
            "Step: 184, Action: 2, Reward: 6.593216732132987\n",
            "Step: 185, Action: 2, Reward: 6.542055016549426\n",
            "Step: 186, Action: 2, Reward: 6.489979189690018\n",
            "Step: 187, Action: 2, Reward: 6.436974884603188\n",
            "Step: 188, Action: 2, Reward: 6.383027754310575\n",
            "Step: 189, Action: 2, Reward: 6.328123491205417\n",
            "Step: 190, Action: 2, Reward: 6.272247847666534\n",
            "Step: 191, Action: 2, Reward: 6.2153866579159\n",
            "Step: 192, Action: 2, Reward: 6.157525861158035\n",
            "Step: 193, Action: 2, Reward: 6.098651526024099\n",
            "Step: 194, Action: 2, Reward: 6.0387498763485326\n",
            "Step: 195, Action: 2, Reward: 5.977807318300847\n",
            "Step: 196, Action: 2, Reward: 5.915810468888054\n",
            "Step: 197, Action: 2, Reward: 5.852746185844637\n",
            "Step: 198, Action: 2, Reward: 5.788601598914056\n",
            "Step: 199, Action: 2, Reward: 5.723364142529732\n",
            "Step: 200, Action: 0, Reward: 7.829815983748745\n"
          ]
        }
      ],
      "source": [
        "# Load the trained model\n",
        "model = DQN.load(\"dqn_auv_navigation\")\n",
        "\n",
        "# Initialize environment\n",
        "env = AUVNavigationEnv()\n",
        "env = Monitor(env)  # Ensure consistency with training\n",
        "obs, _ = env.reset()\n",
        "d_action = []\n",
        "for step in range(200):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, truncated, _ = env.step(int(action))\n",
        "    d_action.append(int(reward))\n",
        "    print(f\"Step: {step+1}, Action: {action}, Reward: {reward}\")\n",
        "\n",
        "    if done or truncated:  # Handle both termination and truncation cases\n",
        "        print(\"Episode Finished. Resetting Environment.\")\n",
        "        obs, _ = env.reset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "l9eG-QWsIOgT",
        "outputId": "04fd6458-336a-4f4e-cbeb-fd2c0a16a9cc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load reward data (Replace with actual reward tracking from your logs)\n",
        "dqn_rewards = np.cumsum(d_action)  # Simulated data\n",
        "ppo_rewards = np.cumsum(p_action)  # Simulated data\n",
        "\n",
        "# Plot cumulative rewards\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(dqn_rewards, label=\"DQN\", color=\"blue\")\n",
        "plt.plot(ppo_rewards, label=\"PPO\", color=\"red\")\n",
        "plt.xlabel(\"Episodes\")\n",
        "plt.ylabel(\"Cumulative Reward\")\n",
        "plt.title(\"DQN vs PPO Cumulative Reward Over Episodes\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "fpeW561HOFNj",
        "outputId": "67da09a9-b148-45b8-d3a5-7272d8b7f376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['rollout/ep_len_mean', 'rollout/ep_rew_mean', 'rollout/exploration_rate', 'time/fps', 'eval/mean_ep_length', 'eval/mean_reward', 'train/learning_rate', 'train/loss']\n",
            "      wall_time   step     value\n",
            "0  1.743105e+09  10400  0.958741\n",
            "1  1.743105e+09  11200  1.538677\n",
            "2  1.743105e+09  12000  0.088199\n",
            "3  1.743105e+09  12800  0.453687\n",
            "4  1.743105e+09  13600  0.363414\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "# Path to TensorBoard logs (replace with your actual log path)\n",
        "log_dir = \"./dqn_auv_log/\"\n",
        "\n",
        "# Get the latest TensorBoard log file\n",
        "event_files = [\"/content/dqn_auv_log/DQN_1/events.out.tfevents.1743105076.e9bee08e862d.696.1\"]\n",
        "\n",
        "event_file = os.path.join(log_dir, event_files[-1])  # Select the latest file\n",
        "\n",
        "# Load TensorBoard logs\n",
        "event_acc = EventAccumulator(event_file, size_guidance={\"scalars\": 0})\n",
        "event_acc.Reload()\n",
        "\n",
        "print(event_acc.Tags()[\"scalars\"])\n",
        "\n",
        "\n",
        "# Extract Loss Values\n",
        "scalars = event_acc.Scalars(\"train/loss\")  # Replace \"train/loss\" with the correct key if needed\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(scalars, columns=[\"wall_time\", \"step\", \"value\"])\n",
        "\n",
        "\n",
        "# Plot Loss Curve\n",
        "plt.plot(df[\"step\"], df[\"value\"], label=\"DQN Loss\")\n",
        "plt.xlabel(\"Timesteps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"DQN Loss Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "wVeYqKSaQwxE",
        "outputId": "841afb88-b4ab-4167-fbf8-f15b58c8046b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['rollout/ep_len_mean', 'rollout/ep_rew_mean', 'time/fps', 'train/approx_kl', 'train/clip_fraction', 'train/clip_range', 'train/entropy_loss', 'train/explained_variance', 'train/learning_rate', 'train/loss', 'train/policy_gradient_loss', 'train/value_loss', 'eval/mean_ep_length', 'eval/mean_reward']\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "# Path to TensorBoard logs (replace with your actual log path)\n",
        "log_dir = \"./ppo_auv_log/\"\n",
        "\n",
        "# Get the latest TensorBoard log file\n",
        "event_files = [\"/content/ppo_auv_log/PPO_2/events.out.tfevents.1743105286.e9bee08e862d.696.2\"]\n",
        "\n",
        "event_file = os.path.join(log_dir, event_files[-1])  # Select the latest file\n",
        "\n",
        "# Load TensorBoard logs\n",
        "event_acc = EventAccumulator(event_file, size_guidance={\"scalars\": 0})\n",
        "event_acc.Reload()\n",
        "\n",
        "print(event_acc.Tags()[\"scalars\"])\n",
        "\n",
        "\n",
        "# Extract Loss Values\n",
        "scalars = event_acc.Scalars(\"train/entropy_loss\")  # Replace \"train/loss\" with the correct key if needed\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(scalars, columns=[\"wall_time\", \"step\", \"value\"])\n",
        "\n",
        "\n",
        "# Plot Loss Curve\n",
        "plt.plot(df[\"step\"], df[\"value\"], label=\"PPO Entropy\")\n",
        "plt.xlabel(\"Timesteps\")\n",
        "plt.ylabel(\"Entropy\")\n",
        "plt.title(\"PPO Entropy Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "426cU8Sg5k2D",
        "outputId": "aefd9ce4-237d-4f82-d103-66b138c09483"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (500, 500) to (512, 512) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulation Video Saved!\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "\n",
        "frames = []\n",
        "obs, _ = env.reset()\n",
        "\n",
        "for _ in range(200):\n",
        "    frame = env.render()  # Now returns an image with obstacles & objects\n",
        "    frames.append(frame)\n",
        "\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = env.step(int(action))\n",
        "\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "# Ensure frames have correct shape (height, width, channels)\n",
        "frames = [frame[:, :, :3] for frame in frames]  # Remove alpha channel if present\n",
        "\n",
        "# Save as a video\n",
        "imageio.mimsave('auv_simulation.mp4', frames, fps=10)\n",
        "print(\"Simulation Video Saved!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
